{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classes.network import RandomNetwork, ScaleFreeNetwork\n",
    "from src.classes.node import Node\n",
    "from src.experimentation import generate_networks, read_and_load_networks, multiple_correlations_par\n",
    "from src.viusalization import plot_cascade_animation, test_significance, calculate_average_per_gamma, plot_cascades_gamma #,plot_cascade_dist_average\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "from collections import defaultdict\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = np.linspace(-1, 1, 11)\n",
    "correlations = np.round(correlations, 1)\n",
    "initial_seeds = np.linspace(13, 1600, 11)\n",
    "num_runs = 30\n",
    "num_nodes = 200\n",
    "update_fraction = 0.1\n",
    "average_degree = 8\n",
    "starting_distribution = 0.5     # L / R ratio (niet per se nodig maar kan misschien leuk zijn om te varieern)\n",
    "p = average_degree/(num_nodes-1) \n",
    "updates = 300000\n",
    "m = 4\n",
    "\n",
    "# vary between random and scale_free\n",
    "# what_net = \"random\"\n",
    "what_net = \"scale_free\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hoi dit is ff uitleg voor jullie voor de nieuwe classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toevoegen van ScaleFreeNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gebruik plot=True om begin plot van distributie te zien\n",
    "# network = ScaleFreeNetwork(m=m, plot=True)\n",
    "\n",
    "# for round in range(10000):\n",
    "#     network.update_round()\n",
    "\n",
    "# # Gebruik deze functie om de distributie te plotten op het einde\n",
    "# network.verify_scale_free_distribution(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toevoegen van RandomNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPV Network() aan te roepen doe je nu RandomNetwork() of ScaleFreeNetwork()\n",
    "# # Je kunt rustig dezelfde argumenten meegeven als bij Network() zoals p=0.1, k=8. Als dit wordt leeggelaaten worden standaard waarden gebruikt.\n",
    "\n",
    "# random_network = RandomNetwork()\n",
    "# for round in range(10000):\n",
    "#     random_network.update_round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developing and saving network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dummy values\n",
    "# num_runs = 10\n",
    "# updates=1000\n",
    "# # scale-free\n",
    "# generate_networks(correlations, initial_seeds, num_nodes=num_nodes, iterations=updates, how_many=num_runs, update_fraction=update_fraction, starting_distribution=starting_distribution, p=p, network_sort=what_net, m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Reading in and generating Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # dummy values\n",
    "# # num_runs = 5\n",
    "# # updates=1000\n",
    "# test=False\n",
    "\n",
    "\n",
    "# # Read in the network and save it in a datastructure\n",
    "# # all_networks = read_and_load_networks(num_runs, num_nodes, update_fraction, average_degree, starting_distribution, correlations, whichtype=what_net)\n",
    "# all_networks = read_and_load_networks(num_runs, num_nodes, update_fraction, average_degree, starting_distribution, correlations, whichtype=\"random\")\n",
    "\n",
    "# # test for consistency of the saved network\n",
    "# if test:\n",
    "#     used_seed = int(initial_seeds[0])\n",
    "#     if what_net == \"scale_free\":\n",
    "#         test_network = ScaleFreeNetwork(num_nodes=num_nodes, m=m, mean=0, correlation=-1.0, update_fraction=update_fraction, starting_distribution=starting_distribution, seed=used_seed)    ### !!!!!!!!!!!!!!\n",
    "#     else: \n",
    "#         test_network = RandomNetwork(num_nodes=num_nodes, mean=0, correlation=-1.0, update_fraction=update_fraction, starting_distribution=starting_distribution, seed=used_seed, p=p)\n",
    "#     number_of_alterations = 0\n",
    "\n",
    "\n",
    "#     assert set([(conn[0].ID, conn[1].ID) for conn in all_networks[(-1.0, 0)][0].connections]) == set([(conn[0].ID, conn[1].ID) for conn in test_network.connections]), \"The networks that are generated should be the same at the start\"\n",
    "\n",
    "#     for _ in range(updates):\n",
    "#         test_network.update_round()\n",
    "#         number_of_alterations += test_network.alterations\n",
    "#         test_network.clean_network()    \n",
    "        \n",
    "#     assert set([(conn[0].ID, conn[1].ID) for conn in all_networks[(-1.0, 0)][1].connections]) == set([(conn[0].ID, conn[1].ID) for conn in test_network.connections]), \"The networks that are generated should be the same at the end\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing and plotting the Cascade distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the cascades (parallelized implementation)\n",
    "### Reading in network and saving everything in datastructures. structured by size and correlation value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datastructures\n",
    "cascades_before = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after = defaultdict(lambda: defaultdict(list))\n",
    "cascades_before_averaged = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after_averaged = defaultdict(lambda: defaultdict(list))\n",
    "save=True\n",
    "sizes = defaultdict()\n",
    "sizes_averaged = defaultdict()\n",
    "\n",
    "cascades_before_averaged_rand = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after_averaged_rand = defaultdict(lambda: defaultdict(list))\n",
    "sizes_averaged_rand = defaultdict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run the cascades for different correlations (for both the initial and updated network), saving the cascade polarizations and cascade sizes in a dictionary\n",
    "for corr in correlations: \n",
    "    print(f\"starting experimentation for correlation: {corr}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "\n",
    "    (before_after, before_after_averaged, largest_sizes) = multiple_correlations_par(corr, num_runs, num_nodes, update_fraction, average_degree, starting_distribution,what_net)\n",
    "    (collection_of_all_before, collection_of_all_after) = before_after\n",
    "    (coll_of_all_before_averaged, coll_of_all_after_averaged) = before_after_averaged\n",
    "    (largest_size_of_all, largest_size_of_all_averaged) = largest_sizes\n",
    "    \n",
    "    # sizes[corr] = largest_size_of_all\n",
    "    # cascades_before[corr] = collection_of_all_before\n",
    "    # cascades_after[corr] = collection_of_all_after\n",
    "\n",
    "    sizes_averaged[corr] = largest_size_of_all_averaged\n",
    "    cascades_before_averaged[corr] = coll_of_all_before_averaged\n",
    "    cascades_after_averaged[corr] = coll_of_all_after_averaged\n",
    "\n",
    "\n",
    "for corr in correlations: \n",
    "    print(f\"starting experimentation for correlation: {corr} (random)\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "\n",
    "    (before_after, before_after_averaged, largest_sizes) = multiple_correlations_par(corr, num_runs, num_nodes, update_fraction, average_degree, starting_distribution,\"random\")\n",
    "    (collection_of_all_before, collection_of_all_after) = before_after\n",
    "    (coll_of_all_before_averaged, coll_of_all_after_averaged) = before_after_averaged\n",
    "    (largest_size_of_all, largest_size_of_all_averaged) = largest_sizes\n",
    "    \n",
    "    sizes_averaged_rand[corr] = largest_size_of_all_averaged\n",
    "    cascades_before_averaged_rand[corr] = coll_of_all_before_averaged\n",
    "    cascades_after_averaged_rand[corr] = coll_of_all_after_averaged\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annimation of cascade size distribution with average polarization. (average cascade size per sampled node is calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cascade_animation(cascades_before_averaged, cascades_after_averaged, list(reversed(correlations)), sizes_averaged, num_runs, what_net, save=True, averaged=True)\n",
    "plot_cascade_animation(cascades_before_averaged_rand, cascades_after_averaged_rand, list(reversed(correlations)), sizes_averaged_rand, num_runs, \"random\", save=True, averaged=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cascades_gamma(cas, num_runs, what_net):\n",
    "    values_bef, values_af, variance_bef, variance_af = calculate_average_per_gamma(cas, num_runs)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "\n",
    "    green_to_red = plt.cm.RdYlGn_r\n",
    "    # Normalize polarization for coloring\n",
    "    keys_bef = list(values_bef.keys())  # Gamma values (X-axis)\n",
    "    sizes_bef = [v[0] for v in values_bef.values()]  # Sizes for Y-axis\n",
    "    pol_bef = [v[1] for v in values_bef.values()]  # Polarization for colors\n",
    "\n",
    "    keys_af = list(values_af.keys())  # Gamma values (X-axis)\n",
    "    sizes_af = [v[0] for v in values_af.values()]  # Sizes for Y-axis\n",
    "    pol_af = [v[1] for v in values_af.values()]  # Polarization for colors\n",
    "\n",
    "    #Coloring scheme with polarization\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    colors_bef = [green_to_red(norm(p)) for p in pol_bef]\n",
    "    colors_af = [green_to_red(norm(p)) for p in pol_af]\n",
    "    \n",
    "    var_sizes_bef = np.array([variance_bef[k][0] for k in keys_bef])  # Variance for sizes (Before)\n",
    "    var_sizes_af = np.array([variance_af[k][0] for k in keys_af])  # Variance for sizes (After)\n",
    "\n",
    "    #Computing confidence interval with calculated variance\n",
    "    sem_sizes_bef = np.sqrt(var_sizes_bef) / np.sqrt(num_runs)\n",
    "    sem_sizes_af = np.sqrt(var_sizes_af) / np.sqrt(num_runs)\n",
    "    ci_sizes_bef = 1.96 * sem_sizes_bef\n",
    "    ci_sizes_af = 1.96 * sem_sizes_af\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=green_to_red, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(\"0:non polarized-1:fully polarized\")\n",
    "    \n",
    "    \n",
    "    # make an errorbar to visualize CI\n",
    "    ax.errorbar(keys_bef, sizes_bef, yerr=ci_sizes_bef, color=\"black\", linewidth = 0.8, capsize=2, label=\"\", linestyle=\"none\", zorder=1)\n",
    "    ax.errorbar(keys_af, sizes_af, yerr=ci_sizes_af, color=\"black\", linewidth=0.8, capsize=2, label=\"\", linestyle=\"none\", zorder=1)\n",
    "\n",
    "    if what_net != \"both\":\n",
    "        label1 = \"Before\"\n",
    "        label2 = \"After\"\n",
    "        marker1 = \"o\"\n",
    "        marker2 = \"s\"\n",
    "    else:\n",
    "        label1 = \"Random\"\n",
    "        label2 = \"Scale-free\"\n",
    "        marker1 = \"v\"\n",
    "        marker2 = \"h\"\n",
    "    for x, y, color in zip(keys_bef, sizes_bef, colors_bef):\n",
    "        ax.scatter(x, y, color=color, edgecolor=\"black\", linewidths=0.5, marker=marker1, s=50, label=\"Before\" if x == keys_bef[0] else \"\", zorder=2)\n",
    "\n",
    "    for x, y, color in zip(keys_af, sizes_af, colors_af):\n",
    "        ax.scatter(x, y, color=color, edgecolor=\"black\", linewidths=0.5, marker=marker2, s=50, label=\"After\" if x == keys_af[0] else \"\", zorder=2)\n",
    "    \n",
    "    \n",
    "    legend_handles = [\n",
    "    plt.Line2D([], [], marker=marker1, color=\"w\", markerfacecolor=\"white\", markersize=6, markeredgecolor=\"black\", label=label1),\n",
    "    plt.Line2D([], [], marker=marker2, color=\"w\", markerfacecolor=\"white\", markersize=6, markeredgecolor=\"black\", label=label2),\n",
    "    ]\n",
    "    ax.set_xlabel(\"Correlation\")\n",
    "    ax.set_ylabel(\"Average Cascade Size\")\n",
    "    # ax.set_title(\"Cascade Size Before and After vs. Gamma\")\n",
    "    ax.legend(handles=legend_handles)\n",
    "\n",
    "    plt.savefig(f\"plots/cascade_distribution/{what_net}/averaged_over_gammas.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarizing all cascade info in one plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,value in cascades_before_averaged.items():\n",
    "#     plot_cascade_dist_average(value, \"before\", largest_size_of_all_averaged, num_runs, save, key)\n",
    "\n",
    "# for key,value in cascades_after_averaged.items():\n",
    "#     plot_cascade_dist_average(value, \"after\", largest_size_of_all_averaged, num_runs, save, key)\n",
    "\n",
    "\n",
    "plot_cascades_gamma((cascades_before_averaged, cascades_after_averaged), num_runs, what_net)\n",
    "plot_cascades_gamma((cascades_after_averaged_rand, cascades_after_averaged), num_runs, \"both\")\n",
    "plot_cascades_gamma((cascades_before_averaged_rand, cascades_after_averaged_rand), num_runs, \"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating significance between cascade sizes and polarizations between networks before and after updating, for different gamma values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_cas = [(cascades_before_averaged, cascades_after_averaged), (cascades_before_averaged_rand, cascades_after_averaged_rand), (cascades_after_averaged_rand, cascades_after_averaged)]\n",
    "\n",
    "for i, what in enumerate([\"scale_free\", \"random\", \"both\"]):\n",
    "    values_bef, values_af, variance_bef, variance_af = calculate_average_per_gamma(which_cas[i], num_runs)\n",
    "    results = test_significance(values_bef, values_af, variance_bef, variance_af, num_runs)\n",
    "    output_file = f\"statistics/cascades/results_bef_af_{what}.txt\"\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f\"Statistical significance for {what} network type (cascade experiments)\\n\")\n",
    "        for gamma, res in results.items():\n",
    "            f.write(f\"Gamma = {gamma}:\\n\")\n",
    "            f.write(f\"  Size: t = {res['t_size']:.3f}, p = {res['p_size']:.3g}\\n\")\n",
    "            f.write(f\"  Polarization: t = {res['t_pol']:.3f}, p = {res['p_pol']:.3g}\\n\")\n",
    "            f.write(\"--------------------------------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
