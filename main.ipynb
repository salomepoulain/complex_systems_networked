{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating, Updating Networks and Polarization Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classes.network import RandomNetwork, ScaleFreeNetwork\n",
    "from src.experimentation import generate_networks, read_and_load_networks, multiple_correlations_par\n",
    "from src.viusalization import plot_cascade_animation, statistics_cascades, plot_cascades_gamma, plot_cascade_dist_average, plot_cascade_power_law\n",
    "from src.assortativity_exp import run_assortativity_experiment, assortativity_significance\n",
    "from src.social_ties_exp import run_social_ties_experiment\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Note\n",
    "Currently, a lot of the directories within the experimentaiton files are set to a dummy directory, to prevent overwriting important data. However, the reading in of data for experimentation are set to the proper directories. So, to experiment with self-generated networks, the directories within experimentation.py should be set to the right ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- correlations: different values of the news correlation\n",
    "- num_runs: number of networks generated for each value of the news correlation\n",
    "- num_nodes: total number of nodes in the network\n",
    "- update_fraction: the fraction of nodes that sample the news directly\n",
    "- starting_distribution: fraction of nodes with identity L\n",
    "- p: probability of creating an edge in a random network\n",
    "- m: number of edges per node in a scale-free network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = np.linspace(-1, 1, 11)\n",
    "correlations = np.round(correlations, 1)\n",
    "initial_seeds = np.linspace(13, 1600, 11)\n",
    "num_runs = 30\n",
    "num_nodes = 200\n",
    "update_fraction = 0.1\n",
    "average_degree = 8\n",
    "starting_distribution = 0.5\n",
    "p = average_degree/(num_nodes-1) \n",
    "updates = 300000\n",
    "m = 4\n",
    "\n",
    "# vary between random and scale_free\n",
    "# what_net = \"random\"\n",
    "what_net = \"scale_free\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplatory Network Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and updating ScaleFreeNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gebruik plot=True om begin plot van distributie te zien\n",
    "# network = ScaleFreeNetwork(m=m, plot=True)\n",
    "\n",
    "# for round in range(10000):\n",
    "#     network.update_round()\n",
    "\n",
    "# # Gebruik deze functie om de distributie te plotten op het einde\n",
    "# network.verify_scale_free_distribution(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and Updating RandomNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPV Network() aan te roepen doe je nu RandomNetwork() of ScaleFreeNetwork()\n",
    "# # Je kunt rustig dezelfde argumenten meegeven als bij Network() zoals p=0.1, k=8. Als dit wordt leeggelaaten worden standaard waarden gebruikt.\n",
    "\n",
    "# random_network = RandomNetwork()\n",
    "# for round in range(10000):\n",
    "#     random_network.update_round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing and saving network\n",
    "This function generates a network (scale-free or random), performs the specified number of updates and reads it out to a .txt file for easy further experimentation. This is done in a parallelized fashion, though it still can take up to 2/3 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dummy values\n",
    "# num_runs = 10\n",
    "# updates=1000\n",
    "# # scale-free\n",
    "# generate_networks(correlations, initial_seeds, num_nodes=num_nodes, iterations=updates, how_many=num_runs, update_fraction=update_fraction, starting_distribution=starting_distribution, p=p, network_sort=what_net, m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Reading in and generating Network\n",
    "\n",
    "These function reads in the networks from the .txt in which they were saved. As the network is fully seeded and thus reproducible, the network can be resimulated with the correct seed and connections. \n",
    "\n",
    "As a check for the validity of the networks, the below test boolean can be set True. This check takes a ~5 minutes.\n",
    "\n",
    "This reading in method of the network is alter used for social ties and assortativity experiments, as this allows for efficient experimentation. For the cascade experiments the networks are read in dynamically, as the running of cascades is done in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # dummy values\n",
    "# # num_runs = 5\n",
    "# # updates=1000\n",
    "\n",
    "# this test only works if the read in network is exactly the same as the generated networks, so check the paths before running!!\n",
    "test=False\n",
    "\n",
    "\n",
    "# Read in the network and save it in a datastructure\n",
    "# all_networks = read_and_load_networks(num_runs, num_nodes, update_fraction, average_degree, starting_distribution, correlations, whichtype=what_net)\n",
    "all_networks = read_and_load_networks(num_runs, num_nodes, update_fraction, average_degree, starting_distribution, correlations, whichtype=\"random\")\n",
    "\n",
    "# test for consistency of the saved network\n",
    "if test:\n",
    "    used_seed = int(initial_seeds[0])\n",
    "    if what_net == \"scale_free\":\n",
    "        test_network = ScaleFreeNetwork(num_nodes=num_nodes, m=m, mean=0, correlation=-1.0, update_fraction=update_fraction, starting_distribution=starting_distribution, seed=used_seed)  \n",
    "    else: \n",
    "        test_network = RandomNetwork(num_nodes=num_nodes, mean=0, correlation=-1.0, update_fraction=update_fraction, starting_distribution=starting_distribution, seed=used_seed, p=p)\n",
    "    number_of_alterations = 0\n",
    "\n",
    "\n",
    "    assert set([(conn[0].ID, conn[1].ID) for conn in all_networks[(-1.0, 0)][0].connections]) == set([(conn[0].ID, conn[1].ID) for conn in test_network.connections]), \"The networks that are generated should be the same at the start\"\n",
    "\n",
    "    for _ in range(updates):\n",
    "        test_network.update_round()\n",
    "        number_of_alterations += test_network.alterations\n",
    "        test_network.clean_network()    \n",
    "        \n",
    "    assert set([(conn[0].ID, conn[1].ID) for conn in all_networks[(-1.0, 0)][1].connections]) == set([(conn[0].ID, conn[1].ID) for conn in test_network.connections]), \"The networks that are generated should be the same at the end\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation (Cascades, Assortativity, Social Ties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascades (Parallelized Implementation)\n",
    "\n",
    "The process begins by reading in the network and organizing data into structures based on cascade size and correlation value.\n",
    "\n",
    "Cascades are run while keeping the network structure fixed, measuring both cascade sizes and polarization. These measurements are used to create distributions. A cascade forms when activated nodes sequentially trigger their neighbors, and cascades merge if they share one or more common nodes. The polarization of a cascade (how imbalanced the proportion of political identities is within it) serves as a metric for overall network polarization.\n",
    "\n",
    "For each correlation value, 30 different networks are analyzed, and 10,000 cascades are run per network. The polarization and prevalence of cascades are then averaged across all 30 runs to ensure consistency.\n",
    "\n",
    "Cascades are tested both before and after network updates to assess how polarization emerges over time. Once distributions are calculated, results are summarized by averaging polarization values and cascade sizes per correlation value. This allows for meaningful comparisons between networks before vs. after updates and between different network topologies (random vs. scale-free)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datastructures for scale-free\n",
    "cascades_before = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after = defaultdict(lambda: defaultdict(list))\n",
    "cascades_before_averaged_sf = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after_averaged_sf = defaultdict(lambda: defaultdict(list))\n",
    "save=True\n",
    "sizes = defaultdict()\n",
    "sizes_averaged = defaultdict()\n",
    "\n",
    "# datatsturctures for random network\n",
    "cascades_before_averaged_rand = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after_averaged_rand = defaultdict(lambda: defaultdict(list))\n",
    "sizes_averaged_rand = defaultdict()\n",
    "\n",
    "# run the cascades for different correlations (for both the initial and updated network), saving the cascade polarizations and cascade sizes in a dictionary\n",
    "# random\n",
    "for corr in correlations: \n",
    "    print(f\"starting experimentation for correlation: {corr}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "\n",
    "    # reads in the scale free networks (30 networks per correlation value) and runs 10 000 cascades per network\n",
    "    (before_after, before_after_averaged, largest_sizes) = multiple_correlations_par(corr, num_runs, num_nodes, update_fraction, average_degree, starting_distribution,what_net)\n",
    "    (collection_of_all_before, collection_of_all_after) = before_after\n",
    "    (coll_of_all_before_averaged, coll_of_all_after_averaged) = before_after_averaged\n",
    "    (largest_size_of_all, largest_size_of_all_averaged) = largest_sizes\n",
    "\n",
    "    # contains a dictionary with the correlation as key, and dictionary as value.\n",
    "    # containing the sizes and number of times size is observed as value (averaged over 30 runs)\n",
    "    # in general, average cascade size per sampled indivudual and the average polarization of this cascade is saved for the metric\n",
    "    sizes_averaged[corr] = largest_size_of_all_averaged\n",
    "    cascades_before_averaged_sf[corr] = coll_of_all_before_averaged\n",
    "    cascades_after_averaged_sf[corr] = coll_of_all_after_averaged\n",
    "\n",
    "# repeat experiments for the scale-free\n",
    "for corr in correlations: \n",
    "    print(f\"starting experimentation for correlation: {corr} (random)\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "\n",
    "    (before_after, before_after_averaged, largest_sizes) = multiple_correlations_par(corr, num_runs, num_nodes, update_fraction, average_degree, starting_distribution,\"random\")\n",
    "    (collection_of_all_before, collection_of_all_after) = before_after\n",
    "    (coll_of_all_before_averaged, coll_of_all_after_averaged) = before_after_averaged\n",
    "    (largest_size_of_all, largest_size_of_all_averaged) = largest_sizes\n",
    "    \n",
    "    # contains a dictionary with the correlation as key, and dictionary as value.\n",
    "    # containing the sizes and number of times size is observed as value (averaged over 30 runs)\n",
    "    # in general, average cascade size per sampled indivudual and the average polarization of this cascade is saved for the metric\n",
    "    sizes_averaged_rand[corr] = largest_size_of_all_averaged\n",
    "    cascades_before_averaged_rand[corr] = coll_of_all_before_averaged\n",
    "    cascades_after_averaged_rand[corr] = coll_of_all_after_averaged\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annimation of cascade size distribution with average polarization \n",
    "uses averaged cascade size per sampled node calculation. Animates the distribution per correlation value.  \n",
    "does this for both the scale free and random network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making animations for both random and scale free\n",
    "plot_cascade_animation(cascades_before_averaged_sf, cascades_after_averaged_sf, list(reversed(correlations)), sizes_averaged, num_runs, what_net, save=True, averaged=True)\n",
    "plot_cascade_animation(cascades_before_averaged_rand, cascades_after_averaged_rand, list(reversed(correlations)), sizes_averaged_rand, num_runs, \"random\", save=True, averaged=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarizing all cascade info in one plot \n",
    "for both the random and scale-free network (before vs after), and random vs scale-free (after updating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the distributions in one plot: for before and after updating for scale free and random, and after updating for scale free vs random\n",
    "plot_cascades_gamma((cascades_before_averaged_sf, cascades_after_averaged_sf), num_runs, what_net)\n",
    "plot_cascades_gamma((cascades_after_averaged_rand, cascades_after_averaged_sf), num_runs, \"both\")\n",
    "plot_cascades_gamma((cascades_before_averaged_rand, cascades_after_averaged_rand), num_runs, \"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase transition at value 0.8\n",
    "\n",
    "visualization of phase transition and fitting a pwerlaw. First fitting the full dist at correlation 0.8 and than zooming in for cascade sizes => 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting raw distribution at transition point\n",
    "plot_cascade_dist_average(cascades_after_averaged_rand[np.float64(0.8)], \"after\", \"random\", sizes_averaged_rand[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "plot_cascade_dist_average(cascades_after_averaged_sf[np.float64(0.8)], \"after\", \"scale_free\", sizes_averaged[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "\n",
    "#plotting zoomed in powerlaw\n",
    "plot_cascade_power_law(cascades_after_averaged_rand[np.float64(0.8)], \"after\", \"random\", sizes_averaged_rand[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "plot_cascade_power_law(cascades_after_averaged_sf[np.float64(0.8)], \"after\", \"scale_free\", sizes_averaged[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical testing \n",
    "calculate significance between random and scale-free (after network is updated), random before and after network is updated and scale-free before vs after network is updated. These values are saved in the folder designated for statistical testing. This is done for different correlation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cas_sf = (cascades_before_averaged_sf, cascades_after_averaged_sf)\n",
    "cas_rand = (cascades_before_averaged_rand, cascades_after_averaged_rand)\n",
    "\n",
    "statistics_cascades(cas_sf, cas_rand, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the assortativity coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assortativity coefficient describes the tendency for a node to connect with another node with the same characteristics. In this context, that characteristic is political identity. If the coefficient is 0, a node with political identity L has the same amount of L and R connections on average. If the coefficient is greater than 0, a node with identity L has more L connections on average. With this in mind, we can you this coefficient as a measure for polarization. \n",
    "\n",
    "For each value of $\\gamma$, there are 30 networks generated and the average, along with the confidence interval at the $p = 95\\%$ confidence level is plotted.\n",
    "\n",
    "We expect that as the news sources diverge, i.e., $\\gamma \\rightarrow -1$, the assorativity will rise. This experiment is done for both the random and the scale-free network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the generated networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_random_networks = read_and_load_networks(num_runs=30, num_nodes=200, update_fraction=0.1, average_degree=8, \n",
    "                                             starting_distribution=0.5, correlations=correlations, whichtype='random')\n",
    "all_scalefree_networks = read_and_load_networks(num_runs=30, num_nodes=200, update_fraction=0.1, average_degree=8, \n",
    "                                                starting_distribution=0.5, correlations=correlations, whichtype='scale_free')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these generated networks, we calculate the assortativity coefficient for both network types and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_assortativity_experiment(all_random_networks, 'random', 30, False, True)\n",
    "run_assortativity_experiment(all_scalefree_networks, 'scale_free', 30, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show that the assortativity coeffienct rises as the news sources diverge, which is in line with our expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if there is significant difference between the assortativity of both networks, we do a Welch T-test with the following null hypothesis:\n",
    "\n",
    "$H_0$: There is no difference between the assortativity coefficient of the random and scale-free network.\n",
    "\n",
    "By comparing the two networks at all the values for $\\gamma$, we find the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assortativity_significance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that for news correlations above 0 there is no difference between the random and scale-free network. For correlations below 0 there is a statistically significant difference between the network types. There is thus less polarization in the scale-free network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net Change in Social Ties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we compare the initial network and the final network and determine if social ties (connections between nodes) are lost/gained depending on the political identity. Again, for each value of $\\gamma$, 30 networks are used and the average and confidence intervals are calculated. \n",
    "\n",
    "We expect that as the news sources diverge, i.e., $\\gamma \\rightarrow -1$, nodes will gain social ties with nodes of the same ideology and lose nodes of the opposing ideology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the same networks are used, we can run the experiment immediately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_social_ties_experiment(all_random_networks, 'random', 30, False)\n",
    "run_social_ties_experiment(all_scalefree_networks, 'scale_free', 30, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that as the news sources diverge, nodes, on average, will gain social ties with nodes of the same ideology and lose nodes with an opposing ideology. This effect decreases as the news becomes more correlated. The difference between the random and the scale-free network is easily visible. The scale-free network has lower average values, meaning that there is less polarization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
