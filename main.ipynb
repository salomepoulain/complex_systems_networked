{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating, Updating Networks and Polarization Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classes.network import RandomNetwork, ScaleFreeNetwork\n",
    "from src.classes.node import Node\n",
    "from src.experimentation import generate_networks, read_and_load_networks, multiple_correlations_par\n",
    "from src.viusalization import plot_cascade_animation, test_significance, calculate_average_per_gamma, plot_cascades_gamma, plot_cascade_dist_average, plot_cascade_power_law\n",
    "from collections import defaultdict\n",
    "from collections import defaultdict\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = np.linspace(-1, 1, 11)\n",
    "correlations = np.round(correlations, 1)\n",
    "initial_seeds = np.linspace(13, 1600, 11)\n",
    "num_runs = 30\n",
    "num_nodes = 200\n",
    "update_fraction = 0.1\n",
    "average_degree = 8\n",
    "starting_distribution = 0.5     # L / R ratio (niet per se nodig maar kan misschien leuk zijn om te varieern)\n",
    "p = average_degree/(num_nodes-1) \n",
    "updates = 300000\n",
    "m = 4\n",
    "\n",
    "# vary between random and scale_free\n",
    "# what_net = \"random\"\n",
    "what_net = \"scale_free\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplatory Network Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and updating ScaleFreeNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gebruik plot=True om begin plot van distributie te zien\n",
    "# network = ScaleFreeNetwork(m=m, plot=True)\n",
    "\n",
    "# for round in range(10000):\n",
    "#     network.update_round()\n",
    "\n",
    "# # Gebruik deze functie om de distributie te plotten op het einde\n",
    "# network.verify_scale_free_distribution(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and Updating RandomNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPV Network() aan te roepen doe je nu RandomNetwork() of ScaleFreeNetwork()\n",
    "# # Je kunt rustig dezelfde argumenten meegeven als bij Network() zoals p=0.1, k=8. Als dit wordt leeggelaaten worden standaard waarden gebruikt.\n",
    "\n",
    "# random_network = RandomNetwork()\n",
    "# for round in range(10000):\n",
    "#     random_network.update_round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing and saving network\n",
    "This function generates a network (scale-free or random), performs the specified number of updates and reads it out to a .txt file for easy further experimentation. This is done in a parallelized fashion, though it still can take up to 2/3 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dummy values\n",
    "# num_runs = 10\n",
    "# updates=1000\n",
    "# # scale-free\n",
    "# generate_networks(correlations, initial_seeds, num_nodes=num_nodes, iterations=updates, how_many=num_runs, update_fraction=update_fraction, starting_distribution=starting_distribution, p=p, network_sort=what_net, m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Reading in and generating Network\n",
    "\n",
    "These function reads in the networks from the .txt in which they were saved. As the network is fully seeded and thus reproducible, the network can be resimulated with the correct seed and connections. \n",
    "\n",
    "As a check for the validity of the networks, the below test boolean can be set True. This check takes a ~5 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # dummy values\n",
    "# # num_runs = 5\n",
    "# # updates=1000\n",
    "\n",
    "# this test only works if the read in network is exactly the same as the generated networks, so check the paths before running!!\n",
    "test=False\n",
    "\n",
    "\n",
    "# Read in the network and save it in a datastructure\n",
    "# all_networks = read_and_load_networks(num_runs, num_nodes, update_fraction, average_degree, starting_distribution, correlations, whichtype=what_net)\n",
    "all_networks = read_and_load_networks(num_runs, num_nodes, update_fraction, average_degree, starting_distribution, correlations, whichtype=\"random\")\n",
    "\n",
    "# test for consistency of the saved network\n",
    "if test:\n",
    "    used_seed = int(initial_seeds[0])\n",
    "    if what_net == \"scale_free\":\n",
    "        test_network = ScaleFreeNetwork(num_nodes=num_nodes, m=m, mean=0, correlation=-1.0, update_fraction=update_fraction, starting_distribution=starting_distribution, seed=used_seed)  \n",
    "    else: \n",
    "        test_network = RandomNetwork(num_nodes=num_nodes, mean=0, correlation=-1.0, update_fraction=update_fraction, starting_distribution=starting_distribution, seed=used_seed, p=p)\n",
    "    number_of_alterations = 0\n",
    "\n",
    "\n",
    "    assert set([(conn[0].ID, conn[1].ID) for conn in all_networks[(-1.0, 0)][0].connections]) == set([(conn[0].ID, conn[1].ID) for conn in test_network.connections]), \"The networks that are generated should be the same at the start\"\n",
    "\n",
    "    for _ in range(updates):\n",
    "        test_network.update_round()\n",
    "        number_of_alterations += test_network.alterations\n",
    "        test_network.clean_network()    \n",
    "        \n",
    "    assert set([(conn[0].ID, conn[1].ID) for conn in all_networks[(-1.0, 0)][1].connections]) == set([(conn[0].ID, conn[1].ID) for conn in test_network.connections]), \"The networks that are generated should be the same at the end\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation (Cascades, Assortativity, Social Ties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the cascades (parallelized implementation)\n",
    "Reading in network and saving everything in datastructures, structured by size and correlation value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datastructures for scale-free\n",
    "cascades_before = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after = defaultdict(lambda: defaultdict(list))\n",
    "cascades_before_averaged_sf = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after_averaged_sf = defaultdict(lambda: defaultdict(list))\n",
    "save=True\n",
    "sizes = defaultdict()\n",
    "sizes_averaged = defaultdict()\n",
    "\n",
    "# datatsturctures for random network\n",
    "cascades_before_averaged_rand = defaultdict(lambda: defaultdict(list))\n",
    "cascades_after_averaged_rand = defaultdict(lambda: defaultdict(list))\n",
    "sizes_averaged_rand = defaultdict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run the cascades for different correlations (for both the initial and updated network), saving the cascade polarizations and cascade sizes in a dictionary\n",
    "for corr in correlations: \n",
    "    print(f\"starting experimentation for correlation: {corr}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "\n",
    "    # reads in the scale free networks (30 networks per correlation value) and runs 10 000 cascades per network\n",
    "    (before_after, before_after_averaged, largest_sizes) = multiple_correlations_par(corr, num_runs, num_nodes, update_fraction, average_degree, starting_distribution,what_net)\n",
    "    (collection_of_all_before, collection_of_all_after) = before_after\n",
    "    (coll_of_all_before_averaged, coll_of_all_after_averaged) = before_after_averaged\n",
    "    (largest_size_of_all, largest_size_of_all_averaged) = largest_sizes\n",
    "\n",
    "    # contains a dictionary with the correlation as key, and dictionary as value.\n",
    "    # containing the sizes and number of times size is observed as value (averaged over 30 runs)\n",
    "    # in general, average cascade size per sampled indivudual and the average polarization of this cascade is saved for the metric\n",
    "    sizes_averaged[corr] = largest_size_of_all_averaged\n",
    "    cascades_before_averaged_sf[corr] = coll_of_all_before_averaged\n",
    "    cascades_after_averaged_sf[corr] = coll_of_all_after_averaged\n",
    "\n",
    "# repeat experiments for the scale-free\n",
    "for corr in correlations: \n",
    "    print(f\"starting experimentation for correlation: {corr} (random)\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "\n",
    "    (before_after, before_after_averaged, largest_sizes) = multiple_correlations_par(corr, num_runs, num_nodes, update_fraction, average_degree, starting_distribution,\"random\")\n",
    "    (collection_of_all_before, collection_of_all_after) = before_after\n",
    "    (coll_of_all_before_averaged, coll_of_all_after_averaged) = before_after_averaged\n",
    "    (largest_size_of_all, largest_size_of_all_averaged) = largest_sizes\n",
    "    \n",
    "    sizes_averaged_rand[corr] = largest_size_of_all_averaged\n",
    "    cascades_before_averaged_rand[corr] = coll_of_all_before_averaged\n",
    "    cascades_after_averaged_rand[corr] = coll_of_all_after_averaged\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annimation of cascade size distribution with average polarization \n",
    "uses averaged cascade size per sampled node calculation. Animates the distribution per correlation value.  \n",
    "does this for both the scale free and random network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making animations for both random and scale free\n",
    "plot_cascade_animation(cascades_before_averaged_sf, cascades_after_averaged_sf, list(reversed(correlations)), sizes_averaged, num_runs, what_net, save=True, averaged=True)\n",
    "plot_cascade_animation(cascades_before_averaged_rand, cascades_after_averaged_rand, list(reversed(correlations)), sizes_averaged_rand, num_runs, \"random\", save=True, averaged=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarizing all cascade info in one plot \n",
    "for both the random and scale-free network (before vs after), and random vs scale-free (after updating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the distributions in one plot: for before and after updating for scale free and random, and after updating for scale free vs random\n",
    "plot_cascades_gamma((cascades_before_averaged_sf, cascades_after_averaged_sf), num_runs, what_net)\n",
    "plot_cascades_gamma((cascades_after_averaged_rand, cascades_after_averaged_sf), num_runs, \"both\")\n",
    "plot_cascades_gamma((cascades_before_averaged_rand, cascades_after_averaged_rand), num_runs, \"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase transition at value 0.8\n",
    "\n",
    "visualization of phase transition and fitting a pwerlaw. First fitting the full dist at correlation 0.8 and than zooming in for cascade sizes => 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting raw distribution at transition point\n",
    "plot_cascade_dist_average(cascades_after_averaged_rand[np.float64(0.8)], \"after\", \"random\", sizes_averaged_rand[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "plot_cascade_dist_average(cascades_after_averaged_sf[np.float64(0.8)], \"after\", \"scale_free\", sizes_averaged[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "\n",
    "#plotting zoomed in powerlaw\n",
    "plot_cascade_power_law(cascades_after_averaged_rand[np.float64(0.8)], \"after\", \"random\", sizes_averaged_rand[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "plot_cascade_power_law(cascades_after_averaged_sf[np.float64(0.8)], \"after\", \"scale_free\", sizes_averaged[np.float64(0.8)], num_runs, save, np.float64(0.8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical testing \n",
    "calculate significance between random and scale-free (after network is updated), random before and after network is updated and scale-free before vs after network is updated. These values are saved in the folder designated for statistical testing. This is done for different correlation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_cas = [(cascades_before_averaged_sf, cascades_after_averaged_sf), (cascades_before_averaged_rand, cascades_after_averaged_rand), (cascades_after_averaged_rand, cascades_after_averaged)]\n",
    "\n",
    "for i, what in enumerate([\"scale_free\", \"random\", \"both\"]):\n",
    "    values_bef, values_af, variance_bef, variance_af = calculate_average_per_gamma(which_cas[i], num_runs)\n",
    "    results = test_significance(values_bef, values_af, variance_bef, variance_af, num_runs)\n",
    "    output_file = f\"statistics/cascades/results_bef_af_{what}.txt\"\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f\"Statistical significance for {what} network type (cascade experiments)\\n\")\n",
    "        for gamma, res in results.items():\n",
    "            f.write(f\"Gamma = {gamma}:\\n\")\n",
    "            f.write(f\"  Size: t = {res['t_size']:.3f}, p = {res['p_size']:.3g}\\n\")\n",
    "            f.write(f\"  Polarization: t = {res['t_pol']:.3f}, p = {res['p_pol']:.3g}\\n\")\n",
    "            f.write(\"--------------------------------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
